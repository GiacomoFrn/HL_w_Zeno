{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2877f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.linalg import expm \n",
    "import matplotlib.pyplot as plt \n",
    "from random import choices, seed \n",
    "from joblib import Parallel, delayed\n",
    "from main.tomography import Hamiltonian_Learning, Pauli_Transfer_Matrix\n",
    "from main.randomized_compiling import RandomizedCompiling\n",
    "import json\n",
    "from qiskit_ibm_runtime import RuntimeEncoder, RuntimeDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "service = QiskitRuntimeService(channel='ibm_cloud', \n",
    "                                token='')\n",
    "backend = service.backend('ibm_brisbane')\n",
    "coupling = backend.configuration().coupling_map\n",
    "\n",
    "qubits_layaout = [13,12,11,10,9,8,7,6,5,4,3,2,1,0,14,\n",
    "                    18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,36,\n",
    "                    51,50,49,48,47,46,45,44,43,42,41,40,39,38,37,52,\n",
    "                    56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,74,\n",
    "                    89,88,87,86,85,84,83,82,81,80,79,78,77,76,75,90,\n",
    "                    94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,112,\n",
    "                    126,125,124,123,122,121,120,119,118,117,116,115,114,113] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6a272",
   "metadata": {},
   "source": [
    "We load the Qiskit results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6252845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datos_100q_RC.json\", \"r\") as file:\n",
    "    results = json.load(file, cls=RuntimeDecoder) \n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499cc1a4",
   "metadata": {},
   "source": [
    "Setting the functions for the postprocessing of the Hamiltonian Learning protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf05dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 109\n",
    "hs = [ 1/8 for j in range(num_qubits) ] # parameters h_j\n",
    "Js = [ 1/16 for j in range(num_qubits-1) ] # Parameters J_j\n",
    "hamil_learn = Hamiltonian_Learning( num_qubits )\n",
    "qubits_tomo = hamil_learn.groups_qubits_tomo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.eye(2)\n",
    "Z = np.diag([1,-1])\n",
    "X = np.array([[0,1],[1,0]])\n",
    "H = (1/8)*np.kron(I,Z) + (1/8)*np.kron(Z,I) + (1/16)*np.kron(X,X)\n",
    "U = expm( -1j*H )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6cdd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = [ prob.data.c.get_counts() for prob in results ]\n",
    "n_shots = int( np.sum([ list(prob.values()) for prob in probs ]) )\n",
    "n_shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544efc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "qubit_coords = {\n",
    "    # (index: (x, y)) coordinates matching the layout you uploaded\n",
    "    0: (0, 0), 1: (1, 0), 2: (2, 0), 3: (3, 0), 4: (4, 0), 5: (5, 0), 6: (6, 0),\n",
    "    7: (7, 0), 8: (8, 0), 9: (9, 0), 10: (10, 0), 11: (11, 0), 12: (12, 0), 13: (13, 0),\n",
    "    14: (0, 1), 15: (4, 1), 16: (8, 1), 17: (12, 1),\n",
    "    18: (0, 2), 19: (1, 2), 20: (2, 2), 21: (3, 2), 22: (4, 2), 23: (5, 2), 24: (6, 2),\n",
    "    25: (7, 2), 26: (8, 2), 27: (9, 2), 28: (10, 2), 29: (11, 2), 30: (12, 2), 31: (13, 2),\n",
    "    32: (14, 2), 33: (2, 3), 34: (6, 3), 35: (10, 3), 36: (14, 3), 37: (0, 4), 38: (1, 4),\n",
    "    39: (2, 4), 40: (3, 4), 41: (4, 4), 42: (5, 4), 43: (6, 4), 44: (7, 4), 45: (8, 4),\n",
    "    46: (9, 4), 47: (10, 4), 48: (11, 4), 49: (12, 4), 50: (13, 4), 51: (14, 4), 52: (0, 5),\n",
    "    53: (4, 5), 54: (8, 5), 55: (12, 5), 56: (0, 6), 57: (1, 6), 58: (2, 6), 59: (3, 6),\n",
    "    60: (4, 6), 61: (5, 6), 62: (6, 6), 63: (7, 6), 64: (8, 6), 65: (9, 6), 66: (10, 6),\n",
    "    67: (11, 6), 68: (12, 6), 69: (13, 6), 70: (14, 6), 71: (2, 7), 72: (6, 7), 73: (10, 7),\n",
    "    74: (14, 7), 75: (0, 8), 76: (1, 8), 77: (2, 8), 78: (3, 8), 79: (4, 8), 80: (5, 8),\n",
    "    81: (6, 8), 82: (7, 8), 83: (8, 8), 84: (9, 8), 85: (10, 8), 86: (11, 8), 87: (12, 8),\n",
    "    88: (13, 8), 89: (14, 8), 90: (0, 9), 91: (4, 9), 92: (8, 9), 93: (12, 9), 94: (0, 10),\n",
    "    95: (1, 10), 96: (2, 10), 97: (3, 10), 98: (4, 10), 99: (5, 10), 100: (6, 10), 101: (7, 10),\n",
    "    102: (8, 10), 103: (9, 10), 104: (10, 10), 105: (11, 10), 106: (12, 10), 107: (13, 10),\n",
    "    108: (14, 10), 109: (2, 11), 110: (6, 11), 111: (10, 11), 112: (14, 11), 113: (1, 12),\n",
    "    114: (2, 12), 115: (3, 12), 116: (4, 12), 117: (5, 12), 118: (6, 12), 119: (7, 12),\n",
    "    120: (8, 12), 121: (9, 12), 122: (10, 12), 123: (11, 12), 124: (12, 12), 125: (13, 12),\n",
    "    126: (14, 12),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af41cda",
   "metadata": {},
   "source": [
    "We execute bootstrapping method to estimate the error of the experimentally estimated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d08ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_resample( probs , j =1 ):\n",
    "    \n",
    "    seed(j)\n",
    "    sampled_probs = []\n",
    "    for prob in probs:\n",
    "        probs_w = list(prob.values())\n",
    "        probs_w =np.array(probs_w) / np.sum(probs_w)\n",
    "        sampled_keys = choices( list(prob.keys()), weights=probs_w,\n",
    "                                k=int( np.sum(list(prob.values())) ) )\n",
    "        sampled_prob = {  key:prob[key] for key in sampled_keys }\n",
    "        sampled_probs.append( sampled_prob )\n",
    "\n",
    "    hamil_learn = Hamiltonian_Learning( num_qubits )\n",
    "    qubits_tomo = hamil_learn.groups_qubits_tomo()\n",
    "    Hs = hamil_learn.hamiltonian_from_tomo( sampled_probs, init=U ) \n",
    "    lambdaa = hamil_learn.noise()\n",
    "\n",
    "    qubits_tomo = np.array( qubits_tomo ).reshape(-1,2)\n",
    "    params_local = { str(j):[] for j in qubits_layaout }\n",
    "    errors_local = { str(j):[] for j in qubits_layaout }\n",
    "    params_two   = {}\n",
    "    errors_two   = {}\n",
    "    for j, (q1, q2) in enumerate(qubits_tomo):\n",
    "        pauli_coef_tomo = Pauli_Transfer_Matrix( Hs[j], num_qubits=2 )  \n",
    "        params_local[str(qubits_layaout[q1])].append( pauli_coef_tomo[0,-1] )\n",
    "        params_local[str(qubits_layaout[q2])].append( pauli_coef_tomo[-1,0] )\n",
    "        params_two[str((qubits_layaout[q1],qubits_layaout[q2]))]= pauli_coef_tomo[1,1]\n",
    "        params_two[str((qubits_layaout[q2],qubits_layaout[q1]))]= pauli_coef_tomo[1,1]\n",
    "\n",
    "        errors_local[str(qubits_layaout[q1])].append( abs(1/8-pauli_coef_tomo[0,-1]) )\n",
    "        errors_local[str(qubits_layaout[q2])].append( abs(1/8-pauli_coef_tomo[-1,0]) )\n",
    "        errors_two[str((qubits_layaout[q1],qubits_layaout[q2]))]= abs(1/16-pauli_coef_tomo[1,1])\n",
    "        errors_two[str((qubits_layaout[q2],qubits_layaout[q1]))]= abs(1/16-pauli_coef_tomo[1,1])\n",
    "\n",
    "    params_local = { j : np.mean(params_local[j]) for j in params_local }\n",
    "    errors_local = { j : np.mean(errors_local[j]) for j in errors_local }\n",
    "\n",
    "    params = { 'params':{'h': params_local,\n",
    "                        'J': params_two },\n",
    "        'error' : {'h' : errors_local,\n",
    "                        'J' : errors_two}, \n",
    "        'coupling' : coupling,\n",
    "        'shots'  :  n_shots, \n",
    "        'lambda' : lambdaa, \n",
    "                }\n",
    "    \n",
    "    return params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e111365",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_mc = Parallel(n_jobs=10)( delayed(bootstrap_resample)( probs, j ) \n",
    "                                for j in range(10000)  )\n",
    "#1000-->70m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82029b82",
   "metadata": {},
   "source": [
    "We create a new Json file with the postprocessed results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_mc = []\n",
    "J_mc = []\n",
    "eh_mc = []\n",
    "eJ_mc = []\n",
    "L_mc = []\n",
    "\n",
    "for params in params_mc:\n",
    "    h_mc.append( params['params']['h'] )\n",
    "    J_mc.append( params['params']['J'] )\n",
    "    eh_mc.append( params['error']['h'] )\n",
    "    eJ_mc.append( params['error']['J'] )\n",
    "    L_mc.append( params['lambda'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78996251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_dict( dicts ):\n",
    "    dict_new = {}\n",
    "    for key in dicts[0].keys():\n",
    "        dict_new[key] = ( float(np.mean([d[key] for d in dicts ])),\n",
    "                            float(np.std([d[key] for d in dicts ])) )\n",
    "    return dict_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07dd4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_local  = mean_dict( h_mc )\n",
    "params_two  = mean_dict( J_mc )\n",
    "errors_local = mean_dict( eh_mc )\n",
    "errors_two = mean_dict( eJ_mc )\n",
    "lambdaa = np.mean( L_mc )\n",
    "lambdaa_std = np.std( L_mc )\n",
    "\n",
    "params = { 'params':{'h': params_local,\n",
    "                        'J': params_two},\n",
    "        'error' : {'h' : errors_local,\n",
    "                        'J' : errors_two}, \n",
    "        'coupling' : coupling,\n",
    "        'shots'  :  n_shots, \n",
    "        'lambda' : (lambdaa,lambdaa_std), \n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d30917",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"params_100q_RC_mc10000.json\", \"w\") as file:\n",
    "        json.dump(params, file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb88e71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78297bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
